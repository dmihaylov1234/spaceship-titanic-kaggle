{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf3ed74-9b9c-46dc-8145-61ba2bf4ab90",
   "metadata": {},
   "source": [
    "# ***Spaceship Titanic - Final Term Project for LING 539***\n",
    "\n",
    "This project is based on an NLP modeling Kaggle challenge, [Spaceship Titanic Competition](https://www.kaggle.com/competitions/spaceship-titanic).\n",
    "\n",
    "The purpose is to predict whether passengers were transported to an alternate dimension during the accident.  \n",
    "This is framed as a **binary classification problem** using structured passenger data.\n",
    "\n",
    "___\n",
    "\n",
    "## Author Information\n",
    "- Name: Dimitri Mihaylov\n",
    "- Email: dmihaylov@arizona.edu\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- Source: [Spaceship Titanic Kaggle Competition](https://www.kaggle.com/competitions/spaceship-titanic)\n",
    "- Files: `train.csv` and `test.csv` provided by Kaggle\n",
    "\n",
    "## Modeling Approach\n",
    "\n",
    "- Preprocessing will include:\n",
    "  - Handling missing values\n",
    "  - Feature engineering (extracting **Deck**, **Cabin Number**, and **Side** from the `Cabin` column)\n",
    "  - Encoding categorical features\n",
    "\n",
    "- Models to be used:\n",
    "  - **Random Forest** with hyperparameter tuning (`GridSearchCV`)\n",
    "  - **XGBoost** classifier\n",
    "\n",
    "- Evaluation metrics to be used:\n",
    "  - **Accuracy**\n",
    "  - **F1-Score**\n",
    "  - Classification reports\n",
    "\n",
    "___\n",
    "\n",
    "# Before Getting Started...\n",
    "## Setup Instructions\n",
    "\n",
    "Before running the notebook, please make sure all necessary packages are installed. The required packages include:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- scikit-learn\n",
    "- xgboost\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To install the dependencies manually, you can use either of the following methods:\n",
    "\n",
    "1. **Using pip**:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "2. **Using Conda**:\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate spaceship-titanic-env\n",
    "```\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933abcb6-18ce-4493-9a58-9ce97d2ec077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: If you encounter the  ~ ModuleNotFoundError: No module named 'xgboost' ~  message, uncomment and run the below line of code:\n",
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e49d7-05d8-482e-a2d7-c9ea5215403d",
   "metadata": {},
   "source": [
    "## Imported Libraries\n",
    "\n",
    "We first import all the libraries needed for data handling, visualization, modeling, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc7d6f4-806f-42a8-bd69-0cf9bed73cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning models and tools\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c26e3-d6a1-490e-b941-85de21775489",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We load the training and test datasets. The training set includes the target variable (`Transported`), while the test set does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d8596e-b51e-4bb9-ac4b-350882d8c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8693, 14)\n",
      "Test shape: (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load training and test datasets\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()\n",
    "\n",
    "# Supresses a warning that is irrelevant\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc71ba-a7a9-4f0a-8622-0486072e23f6",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We handle missing values and encode categorical features to prepare the data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20ebf77-7d4e-440c-a9a1-97f2f6508107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with sensible defaults or median/mode values\n",
    "train_df = train_df.fillna({\n",
    "    'HomePlanet': 'Earth',\n",
    "    'CryoSleep': False,\n",
    "    'Cabin': 'A/0/P',\n",
    "    'Destination': 'TRAPPIST-1e',\n",
    "    'Age': train_df['Age'].median(),\n",
    "    'VIP': False,\n",
    "    'RoomService': 0,\n",
    "    'FoodCourt': 0,\n",
    "    'ShoppingMall': 0,\n",
    "    'Spa': 0,\n",
    "    'VRDeck': 0,\n",
    "    'Name': 'Unknown'\n",
    "}).infer_objects(copy=False)\n",
    "\n",
    "# For test set: use train medians and modes\n",
    "test_df = test_df.fillna(train_df.median(numeric_only=True).to_dict())\n",
    "test_df = test_df.fillna(train_df.mode().iloc[0].to_dict())\n",
    "test_df = test_df.infer_objects(copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8f50c-d8b6-4ce3-894c-f729e142470b",
   "metadata": {},
   "source": [
    "## Feature Engineering: Extract Deck, Cabin Number, and Side\n",
    "\n",
    "We create new features from the `Cabin` column to give the models more structured information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8b3967-1859-489f-ab6c-392cf76ce0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the Cabin column into three new features\n",
    "def process_cabin(df):\n",
    "    df[['Deck', 'CabinNum', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "    df['CabinNum'] = pd.to_numeric(df['CabinNum'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Apply to both datasets\n",
    "train_df = process_cabin(train_df)\n",
    "test_df = process_cabin(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cfa617-7fed-435d-9ad2-c51b7972b5c7",
   "metadata": {},
   "source": [
    "## Encode Categorical Columns\n",
    "\n",
    "We convert categorical text columns into numbers so that machine learning models can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6490590-d014-48ce-9a68-e39e714b060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode boolean-like columns using Label Encoding (0 and 1)\n",
    "label_cols = ['CryoSleep', 'VIP']\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "\n",
    "# One-hot encode multi-class categorical columns\n",
    "categorical_cols = ['HomePlanet', 'Destination', 'Deck', 'Side']\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_cols)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_cols)\n",
    "\n",
    "# Align columns in test set to match train set \n",
    "train_df, test_df = train_df.align(test_df, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9bed5-aedd-4dc2-b254-f1e145550d8e",
   "metadata": {},
   "source": [
    "## Define Features and Target Variable\n",
    "\n",
    "We select the columns we want to use for modeling and define our prediction target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29df4e2c-27f8-4000-8859-5adc346b678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns include numerical, engineered, and encoded categorical variables\n",
    "features = [\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'VIP', 'CryoSleep', 'CabinNum'\n",
    "] + [col for col in train_df.columns if col.startswith(('HomePlanet_', 'Destination_', 'Deck_', 'Side_'))]\n",
    "\n",
    "# Input features\n",
    "X = train_df[features]\n",
    "\n",
    "# Target: Transported (converted to 0 or 1)\n",
    "y = train_df['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc78995-a82d-41cd-b70f-be278ea4ed78",
   "metadata": {},
   "source": [
    "## Train/Validation Split\n",
    "\n",
    "We split the data so we can evaluate our model on unseen data (validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "412acd55-7b95-4230-9503-0f065eb4957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% training and 20% validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c055606-5be8-4a92-bf5f-a548820746d6",
   "metadata": {},
   "source": [
    "## Random Forest: Hyperparameter Tuning\n",
    "\n",
    "We use GridSearchCV to try different settings of the Random Forest model and find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbadde6d-c6ae-410f-ada5-5d2dbdcd488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.79700977573318\n",
      "Random Forest F1 Score: 0.8033426183844011\n"
     ]
    }
   ],
   "source": [
    "# Define grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "rf_preds = best_rf.predict(X_valid)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_valid, rf_preds))\n",
    "print(\"Random Forest F1 Score:\", f1_score(y_valid, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33801c3-5ec6-4567-8abd-5495c6f36739",
   "metadata": {},
   "source": [
    "## XGBoost Model\n",
    "\n",
    "We try a more powerful model, XGBoost, to see if we can improve our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c8aa1f-1437-47fa-b6c6-70b5d8344d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Accuracy: 0.8050603795284647\n",
      "XGBoost F1 Score: 0.807495741056218\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "xgb_preds = xgb_model.predict(X_valid)\n",
    "print(\"\\nXGBoost Accuracy:\", accuracy_score(y_valid, xgb_preds))\n",
    "print(\"XGBoost F1 Score:\", f1_score(y_valid, xgb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b806a-5f3f-427b-84ab-3c65c7b57dab",
   "metadata": {},
   "source": [
    "## Compare Models\n",
    "\n",
    "We print detailed classification reports to compare Random Forest and XGBoost side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8deff2f1-5e47-48a1-80b6-5497a273c4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Reports ---\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       861\n",
      "           1       0.79      0.82      0.80       878\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n",
      "XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       861\n",
      "           1       0.81      0.81      0.81       878\n",
      "\n",
      "    accuracy                           0.81      1739\n",
      "   macro avg       0.81      0.81      0.81      1739\n",
      "weighted avg       0.81      0.81      0.81      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Classification Reports ---\")\n",
    "print(\"Random Forest:\\n\", classification_report(y_valid, rf_preds))\n",
    "print(\"XGBoost:\\n\", classification_report(y_valid, xgb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebce8b-dc8e-4820-a131-b4aff49056be",
   "metadata": {},
   "source": [
    "## Predict on Test Set & Save Submission\n",
    "\n",
    "We generate predictions on the test set and save them in the format required for Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78c915b5-902d-4ae7-b924-007f3e4457b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "# Use XGBoost model (or best performing one)\n",
    "test_preds = xgb_model.predict(test_df[features])\n",
    "test_preds = test_preds.astype(bool)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Transported': test_preds})\n",
    "\n",
    "# Save as CSV\n",
    "submission.to_csv('../submission.csv', index=False)\n",
    "print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985639c4-629b-4e1b-aa42-db0b706eeedd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored machine learning models to predict passenger transportation on the Spaceship Titanic dataset. \n",
    "\n",
    "- We began by preprocessing the data, handling missing values, and engineering new features (like extracting `Deck`, `CabinNum`, and `Side` from the `Cabin` column)\n",
    "- We then encoded categorical variables and selected features for modeling\n",
    "- Two models were trained and evaluated:\n",
    "  - A **Random Forest Classifier** with hyperparameter tuning\n",
    "  - An **XGBoost Classifier** for improved performance\n",
    "\n",
    "Both models achieved strong accuracy and F1 scores, with XGBoost slightly outperforming Random Forest in this case.  \n",
    "\n",
    "For future improvements:\n",
    "- We could further engineer features (i.e., parsing passenger names or creating interaction terms)\n",
    "- We could handle outliers in the spending columns\n",
    "- We could experiment with model stacking or more advanced ensemble methods\n",
    "- We could tune hyperparameters more exhaustively for XGBoost and other models\n",
    "\n",
    "Below is a screenshot of the submitted CSV to Kaggle, along with the score result from the submission:\n",
    "\n",
    "\n",
    "![SCREENSHOT](kaggle_submission.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
